---
date: 2019-02-16T11:25:00-01:00
title: "How to Survive the Titanic"
excerpt: "On April 10th, 1912, the RMS *Titanic* departed on its maiden voyage from Southampton to New York City. After making stops in Cherbourg and Queenstown to pick up additional passengers, the ship headed towards New York."
description: "Titanic Data Analysis"
teaser_image_path: /assets/images/color_graph_small.jpg
# category:
tags: ["Python", "Machine Learning", "Random Forest"]
classes: wide
author_profile: true
type: posts
header:
  overlay_color: "#4281f5"
---


# Introduction
On April 10th, 1912, the RMS *Titanic* departed on its maiden voyage from Southampton to New York City. After making stops in Cherbourg and Queenstown to pick up additional passengers, the ship headed towards New York. There were 2,224 passengers including 892 crew members aboard the ship. This was under the ship's capacity of around 3,300. The ship was equipped with watertight compartments that were designed to fill up in the event of a breach to the ship's hull. This technology was said to make the ship "unsinkable". 

The *Titanic*  was scheduled to arrive at New York Pier 59 on the morning of April 17th. But at around 11:40 p.m. on the night of April 14th, the ship collided with an iceberg. The ship's hull was not punctured by the collision, however it weakened the seams of the hull causing them to separate. Several watertight compartments filled with water and the ship eventually sank in the Atlantic Ocean about 400 miles off the coast of Newfoundland.

Distress signals were sent out, but no ships were near enough to reach the *Titanic*  before she sank. At around 4 a.m., the the RMS *Carpathia*  arrived on scene in response to the distress signals The ship had 20 lifeboats which had capacity for only 1,178 passengers. Approximately 1,500 people lost their lives in this tragic event. About 710 people survived and were taken to New York via the *Carpathia*.  

So, who were the passengers that survived this tragedy? Fortunately, we have data which can give us insight into who survived and who perished. The goal is to use machine learning methods to identify patterns in the data to predict which passengers survived and which ones did not. 

## The Dataset
The Titanic dataset comes from kaggle. The training set contains **891 rows and 12 columns** with one row per passenger. The test set includes 418 rows and 11 columns (the survived column is missing for the sake of the competition).

The columns of the test set are:
* **PassengerId**: Kaggle passenger id
* **Survived**: 1 = passenger survived, 0 = passenger did not survive
* **Pclass**: Ticket class
* **Name**: Full name of passenger including title
* **Sex**: Sex of passenger
* **Age**: Age of passenger
* **SibSp**: Number of siblings and spouses aboard the ship
* **Parch**: Number of parents and children aboard the ship
* **Ticket**: Ticket number
* **Fare**: Passenger fare
* **Cabin**: Cabin number
* **Embarked**: Port of embarkation

## Goal of Analysis


sources: 
* https://en.wikipedia.org/wiki/RMS_Titanic
* https://www.kaggle.com/c/titanic/data

# Import Data

## Load the standard Libraries
First, load the standard python libraries.


```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

%matplotlib inline
```

Next, we import the training data from the *train.csv*  file and save it as **data**. After the data is loaded into our jupyter notebook, we convert it into a pandas dataframe and inspect it. 


```python
# import train data and save it as data
data = pd.read_csv('train.csv')

# load data into a pandas dataframe and save as df
df = pd.DataFrame(data)

df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>



# Data Exploration
Now that the data is loaded, we can begin exploration. The data has already been split into training and test sets. We will explore the training set and act as if the test set is not available to us at this time. This will allow us to get a better measure of the accuracy our model and avoid over fitting.

The describe function is used to view summaries of the numerical columns in the dataset. This also helps to identify columns with null values. Notice the count of Age compared to the other columns.


```python
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>



The corr method calculates the correlation between variables. 


```python
c = df.corr()
c
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>PassengerId</th>
      <td>1.000000</td>
      <td>-0.005007</td>
      <td>-0.035144</td>
      <td>0.036847</td>
      <td>-0.057527</td>
      <td>-0.001652</td>
      <td>0.012658</td>
    </tr>
    <tr>
      <th>Survived</th>
      <td>-0.005007</td>
      <td>1.000000</td>
      <td>-0.338481</td>
      <td>-0.077221</td>
      <td>-0.035322</td>
      <td>0.081629</td>
      <td>0.257307</td>
    </tr>
    <tr>
      <th>Pclass</th>
      <td>-0.035144</td>
      <td>-0.338481</td>
      <td>1.000000</td>
      <td>-0.369226</td>
      <td>0.083081</td>
      <td>0.018443</td>
      <td>-0.549500</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>0.036847</td>
      <td>-0.077221</td>
      <td>-0.369226</td>
      <td>1.000000</td>
      <td>-0.308247</td>
      <td>-0.189119</td>
      <td>0.096067</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>-0.057527</td>
      <td>-0.035322</td>
      <td>0.083081</td>
      <td>-0.308247</td>
      <td>1.000000</td>
      <td>0.414838</td>
      <td>0.159651</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>-0.001652</td>
      <td>0.081629</td>
      <td>0.018443</td>
      <td>-0.189119</td>
      <td>0.414838</td>
      <td>1.000000</td>
      <td>0.216225</td>
    </tr>
    <tr>
      <th>Fare</th>
      <td>0.012658</td>
      <td>0.257307</td>
      <td>-0.549500</td>
      <td>0.096067</td>
      <td>0.159651</td>
      <td>0.216225</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Get a count of all columns including text fields
df.count()
```




    PassengerId    891
    Survived       891
    Pclass         891
    Name           891
    Sex            891
    Age            714
    SibSp          891
    Parch          891
    Ticket         891
    Fare           891
    Cabin          204
    Embarked       889
    dtype: int64



## Explore Age


```python
# Unique values for age
df.Age.unique()
```




    array([22.  , 38.  , 26.  , 35.  ,   nan, 54.  ,  2.  , 27.  , 14.  ,
            4.  , 58.  , 20.  , 39.  , 55.  , 31.  , 34.  , 15.  , 28.  ,
            8.  , 19.  , 40.  , 66.  , 42.  , 21.  , 18.  ,  3.  ,  7.  ,
           49.  , 29.  , 65.  , 28.5 ,  5.  , 11.  , 45.  , 17.  , 32.  ,
           16.  , 25.  ,  0.83, 30.  , 33.  , 23.  , 24.  , 46.  , 59.  ,
           71.  , 37.  , 47.  , 14.5 , 70.5 , 32.5 , 12.  ,  9.  , 36.5 ,
           51.  , 55.5 , 40.5 , 44.  ,  1.  , 61.  , 56.  , 50.  , 36.  ,
           45.5 , 20.5 , 62.  , 41.  , 52.  , 63.  , 23.5 ,  0.92, 43.  ,
           60.  , 10.  , 64.  , 13.  , 48.  ,  0.75, 53.  , 57.  , 80.  ,
           70.  , 24.5 ,  6.  ,  0.67, 30.5 ,  0.42, 34.5 , 74.  ])




```python
# distribution of passengers by age
df.groupby(pd.qcut(df['Age'],10))['Survived'].mean().plot(figsize=(8,6), kind='bar', color='blue', alpha=.2)
```





<figure>
	<a href="/assets/images/titanic/output_13_1.png"><img src="/assets/images/titanic/output_13_1.png"></a>
</figure>



## Explore P Class


```python
df['Pclass'].value_counts(dropna = False)
```




    3    491
    1    216
    2    184
    Name: Pclass, dtype: int64




```python
# Survivors by Pclass
```

## Explore Pclass


```python
df.groupby('Pclass').describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">Age</th>
      <th colspan="2" halign="left">Fare</th>
      <th>...</th>
      <th colspan="2" halign="left">SibSp</th>
      <th colspan="8" halign="left">Survived</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
      <th>count</th>
      <th>mean</th>
      <th>...</th>
      <th>75%</th>
      <th>max</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Pclass</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>186.0</td>
      <td>38.233441</td>
      <td>14.802856</td>
      <td>0.92</td>
      <td>27.0</td>
      <td>37.0</td>
      <td>49.0</td>
      <td>80.0</td>
      <td>216.0</td>
      <td>84.154687</td>
      <td>...</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>216.0</td>
      <td>0.629630</td>
      <td>0.484026</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>173.0</td>
      <td>29.877630</td>
      <td>14.001077</td>
      <td>0.67</td>
      <td>23.0</td>
      <td>29.0</td>
      <td>36.0</td>
      <td>70.0</td>
      <td>184.0</td>
      <td>20.662183</td>
      <td>...</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>184.0</td>
      <td>0.472826</td>
      <td>0.500623</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>355.0</td>
      <td>25.140620</td>
      <td>12.495398</td>
      <td>0.42</td>
      <td>18.0</td>
      <td>24.0</td>
      <td>32.0</td>
      <td>74.0</td>
      <td>491.0</td>
      <td>13.675550</td>
      <td>...</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>491.0</td>
      <td>0.242363</td>
      <td>0.428949</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 48 columns</p>
</div>



### Survivors by Pclass


```python
df.groupby('Pclass')['Survived'].mean()
```




    Pclass
    1    0.629630
    2    0.472826
    3    0.242363
    Name: Survived, dtype: float64




```python
df.groupby('Pclass')['Survived'].mean().plot(kind='bar',width=0.8)
```




<figure>
	<a href="/assets/images/titanic/output_21_1.png"><img src="/assets/images/titanic/output_21_1.png"></a>
</figure>



## Explore Embarked Location


```python
df['Embarked'].value_counts(dropna = False)
```




    S      644
    C      168
    Q       77
    NaN      2
    Name: Embarked, dtype: int64




```python
pd.crosstab(df['Pclass'],df['Embarked'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Embarked</th>
      <th>C</th>
      <th>Q</th>
      <th>S</th>
    </tr>
    <tr>
      <th>Pclass</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>85</td>
      <td>2</td>
      <td>127</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17</td>
      <td>3</td>
      <td>164</td>
    </tr>
    <tr>
      <th>3</th>
      <td>66</td>
      <td>72</td>
      <td>353</td>
    </tr>
  </tbody>
</table>
</div>



### Survivors by Embarked Location


```python
df.groupby('Embarked')['Survived'].mean()
```




    Embarked
    C    0.553571
    Q    0.389610
    S    0.336957
    Name: Survived, dtype: float64




```python
df.groupby('Embarked')['Survived'].mean().plot(kind='bar',width=0.8)
```




<figure>
	<a href="/assets/images/titanic/output_27_1.png"><img src="/assets/images/titanic/output_27_1.png"></a>
</figure>



# Feature Engineering
## Age Binning
To make the age field more informative, we can group passengers into age bins.


```python
df['age_bin'] = pd.qcut(df['Age'],10)
```


```python
pd.crosstab(df['age_bin'],df['SibSp'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>SibSp</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
    <tr>
      <th>age_bin</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(0.419, 14.0]</th>
      <td>20</td>
      <td>24</td>
      <td>6</td>
      <td>7</td>
      <td>16</td>
      <td>4</td>
    </tr>
    <tr>
      <th>(14.0, 19.0]</th>
      <td>60</td>
      <td>20</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>(19.0, 22.0]</th>
      <td>55</td>
      <td>9</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(22.0, 25.0]</th>
      <td>48</td>
      <td>15</td>
      <td>5</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(25.0, 28.0]</th>
      <td>45</td>
      <td>14</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(28.0, 31.8]</th>
      <td>47</td>
      <td>18</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(31.8, 36.0]</th>
      <td>63</td>
      <td>26</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(36.0, 41.0]</th>
      <td>34</td>
      <td>17</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(41.0, 50.0]</th>
      <td>50</td>
      <td>26</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>(50.0, 80.0]</th>
      <td>49</td>
      <td>14</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.crosstab(df['Parch'],df['SibSp'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>SibSp</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>8</th>
    </tr>
    <tr>
      <th>Parch</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>537</td>
      <td>123</td>
      <td>16</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38</td>
      <td>57</td>
      <td>7</td>
      <td>7</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>29</td>
      <td>19</td>
      <td>4</td>
      <td>7</td>
      <td>9</td>
      <td>5</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df['family_members']=df['Parch']+df['SibSp']
```


```python
df.groupby('family_members')['Survived'].agg(['mean', 'size'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>size</th>
    </tr>
    <tr>
      <th>family_members</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.303538</td>
      <td>537</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.552795</td>
      <td>161</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.578431</td>
      <td>102</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.724138</td>
      <td>29</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.200000</td>
      <td>15</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.136364</td>
      <td>22</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.333333</td>
      <td>12</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.000000</td>
      <td>6</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.000000</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.groupby('age_bin')['Survived'].mean()
```




    age_bin
    (0.419, 14.0]    0.584416
    (14.0, 19.0]     0.390805
    (19.0, 22.0]     0.283582
    (22.0, 25.0]     0.371429
    (25.0, 28.0]     0.393443
    (28.0, 31.8]     0.393939
    (31.8, 36.0]     0.483516
    (36.0, 41.0]     0.358491
    (41.0, 50.0]     0.397436
    (50.0, 80.0]     0.343750
    Name: Survived, dtype: float64



## Replacing Null Values of Age


```python
# Save median age of train set to use with transform of test set
med_age = df["Age"].median()

# Replace null values of age with median age
df["Age_Fill_Med"] = df["Age"].fillna(med_age)
```

## Get Title From Name


```python
df['Title'] = df['Name'].apply(lambda s: s.split(', ', 1)[1].split(' ',1)[0])
```


```python
#s=df['Name'].str.split(', ', 1)
```


```python
pd.crosstab(df['Title'],df['family_members'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>family_members</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>10</th>
    </tr>
    <tr>
      <th>Title</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Capt.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Col.</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Don.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Dr.</th>
      <td>5</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Jonkheer.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Lady.</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Major.</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Master.</th>
      <td>0</td>
      <td>3</td>
      <td>15</td>
      <td>4</td>
      <td>2</td>
      <td>9</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Miss.</th>
      <td>100</td>
      <td>27</td>
      <td>22</td>
      <td>10</td>
      <td>9</td>
      <td>4</td>
      <td>6</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Mlle.</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Mme.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Mr.</th>
      <td>397</td>
      <td>68</td>
      <td>35</td>
      <td>6</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Mrs.</th>
      <td>20</td>
      <td>59</td>
      <td>27</td>
      <td>9</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Ms.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Rev.</th>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Sir.</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>the</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.groupby('Title').describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">Age</th>
      <th colspan="2" halign="left">Age_Fill_Med</th>
      <th>...</th>
      <th colspan="2" halign="left">Survived</th>
      <th colspan="8" halign="left">family_members</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
      <th>count</th>
      <th>mean</th>
      <th>...</th>
      <th>75%</th>
      <th>max</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Title</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Capt.</th>
      <td>1.0</td>
      <td>70.000000</td>
      <td>NaN</td>
      <td>70.00</td>
      <td>70.000</td>
      <td>70.0</td>
      <td>70.00</td>
      <td>70.0</td>
      <td>1.0</td>
      <td>70.000000</td>
      <td>...</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.000000</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.00</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Col.</th>
      <td>2.0</td>
      <td>58.000000</td>
      <td>2.828427</td>
      <td>56.00</td>
      <td>57.000</td>
      <td>58.0</td>
      <td>59.00</td>
      <td>60.0</td>
      <td>2.0</td>
      <td>58.000000</td>
      <td>...</td>
      <td>0.75</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Don.</th>
      <td>1.0</td>
      <td>40.000000</td>
      <td>NaN</td>
      <td>40.00</td>
      <td>40.000</td>
      <td>40.0</td>
      <td>40.00</td>
      <td>40.0</td>
      <td>1.0</td>
      <td>40.000000</td>
      <td>...</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Dr.</th>
      <td>6.0</td>
      <td>42.000000</td>
      <td>12.016655</td>
      <td>23.00</td>
      <td>35.000</td>
      <td>46.5</td>
      <td>49.75</td>
      <td>54.0</td>
      <td>7.0</td>
      <td>40.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>0.571429</td>
      <td>0.975900</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Jonkheer.</th>
      <td>1.0</td>
      <td>38.000000</td>
      <td>NaN</td>
      <td>38.00</td>
      <td>38.000</td>
      <td>38.0</td>
      <td>38.00</td>
      <td>38.0</td>
      <td>1.0</td>
      <td>38.000000</td>
      <td>...</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Lady.</th>
      <td>1.0</td>
      <td>48.000000</td>
      <td>NaN</td>
      <td>48.00</td>
      <td>48.000</td>
      <td>48.0</td>
      <td>48.00</td>
      <td>48.0</td>
      <td>1.0</td>
      <td>48.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Major.</th>
      <td>2.0</td>
      <td>48.500000</td>
      <td>4.949747</td>
      <td>45.00</td>
      <td>46.750</td>
      <td>48.5</td>
      <td>50.25</td>
      <td>52.0</td>
      <td>2.0</td>
      <td>48.500000</td>
      <td>...</td>
      <td>0.75</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Master.</th>
      <td>36.0</td>
      <td>4.574167</td>
      <td>3.619872</td>
      <td>0.42</td>
      <td>1.000</td>
      <td>3.5</td>
      <td>8.00</td>
      <td>12.0</td>
      <td>40.0</td>
      <td>6.916750</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>40.0</td>
      <td>3.675000</td>
      <td>2.092569</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>5.00</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Miss.</th>
      <td>146.0</td>
      <td>21.773973</td>
      <td>12.990292</td>
      <td>0.75</td>
      <td>14.125</td>
      <td>21.0</td>
      <td>30.00</td>
      <td>63.0</td>
      <td>182.0</td>
      <td>23.005495</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>182.0</td>
      <td>1.263736</td>
      <td>1.999089</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.00</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Mlle.</th>
      <td>2.0</td>
      <td>24.000000</td>
      <td>0.000000</td>
      <td>24.00</td>
      <td>24.000</td>
      <td>24.0</td>
      <td>24.00</td>
      <td>24.0</td>
      <td>2.0</td>
      <td>24.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Mme.</th>
      <td>1.0</td>
      <td>24.000000</td>
      <td>NaN</td>
      <td>24.00</td>
      <td>24.000</td>
      <td>24.0</td>
      <td>24.00</td>
      <td>24.0</td>
      <td>1.0</td>
      <td>24.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Mr.</th>
      <td>398.0</td>
      <td>32.368090</td>
      <td>12.708793</td>
      <td>11.00</td>
      <td>23.000</td>
      <td>30.0</td>
      <td>39.00</td>
      <td>80.0</td>
      <td>517.0</td>
      <td>31.362669</td>
      <td>...</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>517.0</td>
      <td>0.441006</td>
      <td>1.154239</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Mrs.</th>
      <td>108.0</td>
      <td>35.898148</td>
      <td>11.433628</td>
      <td>14.00</td>
      <td>27.750</td>
      <td>35.0</td>
      <td>44.00</td>
      <td>63.0</td>
      <td>125.0</td>
      <td>34.824000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>125.0</td>
      <td>1.528000</td>
      <td>1.347495</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.00</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>Ms.</th>
      <td>1.0</td>
      <td>28.000000</td>
      <td>NaN</td>
      <td>28.00</td>
      <td>28.000</td>
      <td>28.0</td>
      <td>28.00</td>
      <td>28.0</td>
      <td>1.0</td>
      <td>28.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Rev.</th>
      <td>6.0</td>
      <td>43.166667</td>
      <td>13.136463</td>
      <td>27.00</td>
      <td>31.500</td>
      <td>46.5</td>
      <td>53.25</td>
      <td>57.0</td>
      <td>6.0</td>
      <td>43.166667</td>
      <td>...</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>0.333333</td>
      <td>0.516398</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.75</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Sir.</th>
      <td>1.0</td>
      <td>49.000000</td>
      <td>NaN</td>
      <td>49.00</td>
      <td>49.000</td>
      <td>49.0</td>
      <td>49.00</td>
      <td>49.0</td>
      <td>1.0</td>
      <td>49.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>the</th>
      <td>1.0</td>
      <td>33.000000</td>
      <td>NaN</td>
      <td>33.00</td>
      <td>33.000</td>
      <td>33.0</td>
      <td>33.00</td>
      <td>33.0</td>
      <td>1.0</td>
      <td>33.000000</td>
      <td>...</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>17 rows × 72 columns</p>
</div>




```python
df['Title'].value_counts()>10
```




    Mr.           True
    Miss.         True
    Mrs.          True
    Master.       True
    Dr.          False
    Rev.         False
    Mlle.        False
    Col.         False
    Major.       False
    Jonkheer.    False
    Mme.         False
    Sir.         False
    Don.         False
    Ms.          False
    Capt.        False
    Lady.        False
    the          False
    Name: Title, dtype: bool




```python
frequencies = df['Title'].value_counts()

condition = frequencies<10   # you can define it however you want
mask_obs = frequencies[condition].index
mask_dict = dict.fromkeys(mask_obs, 'Other')

df['New_Title'] = df['Title'].replace(mask_dict) 
```


```python
title_dict=df.groupby('New_Title')['Age'].median().to_dict()
idx=df['Age'].isnull()
# df.loc[idx,"Age"]=
df['Age2']=df['Age'].copy()
df.loc[idx,'Age2']=df.loc[idx,"New_Title"].map(title_dict)
```


```python
df.loc[idx,['New_Title','Age','Age2']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>New_Title</th>
      <th>Age</th>
      <th>Age2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>Mr.</td>
      <td>NaN</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Mr.</td>
      <td>NaN</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Mrs.</td>
      <td>NaN</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Mr.</td>
      <td>NaN</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Miss.</td>
      <td>NaN</td>
      <td>21.0</td>
    </tr>
  </tbody>
</table>
</div>



## Replace Null Values of Fare


```python
fare_median = df["Fare"].median()
fare_median
```




    14.4542



## Creating Dummy Variables for Embarked and Sex


```python
from sklearn import preprocessing
```


```python
df = pd.get_dummies(df,columns=['Embarked','Sex'],drop_first=True)
```


```python
le = preprocessing.LabelEncoder()
le.fit(["C", "Q", "S"])
list(le.classes_)
```




    ['C', 'Q', 'S']



# Fit the Model



```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
```


```python
y = df['Survived']

X = df[['Age_Fill_Med','Pclass','Sex_male','Fare']]
```

## Random Forest Model and Cross Validation


```python
# Original Random Forest with Eyal
rf = RandomForestClassifier(n_estimators=20,random_state=0)

# # Random Forest with Null Ages replaced with Median of Age
s1 = cross_val_score(rf,X,y,cv=10)

print('X: '+'{:.2f}% +- {:.2f}%'.format(100*np.mean(s1),100*np.std(s1)))
```

    X: 80.93% +- 4.03%
    

## Randomized Grid Search
Grid Search will test various hyperparameters and choose the best values for each. With a Random Forest classifier we have 3 main hyperparameters, max depth, max features, and min samples split. 

**Max depth** is the depth of each tree in the forest. The depth is the number of splits a tree has. For example, setting max_depth = 3 will limit the number of splits per tree to 3.

**Max features** is the number of features in each tree. Limiting the number of features will prevent overfitting.

**Min samples split** is the number of records required to split on a given node. For example, the model with not split again if the number of records is less than this parameter.


```python
from sklearn.model_selection import RandomizedSearchCV
from time import time
from scipy.stats import randint as sp_randint

def report(results, n_top=3):
    for i in range(1, n_top + 1):
        candidates = np.flatnonzero(results['rank_test_score'] == i)
        for candidate in candidates:
            print("Model with rank: {0}".format(i))
            print("Mean validation score: {0:.3f} (std: {1:.3f})".format(
                  results['mean_test_score'][candidate],
                  results['std_test_score'][candidate]))
            print("Parameters: {0}".format(results['params'][candidate]))
            print("")
            
```


```python
# specify parameters and distributions to sample from
param_dist = {"max_depth": [3, None],
              "max_features": sp_randint(1,5),
              "min_samples_split": sp_randint(2, 11),
              "bootstrap": [True, False],
              "criterion": ["gini", "entropy"],
              "n_estimators": sp_randint(10,100)}

# run randomized search
n_iter_search = 30
random_search = RandomizedSearchCV(rf, param_distributions=param_dist,
                                   n_iter=n_iter_search, cv=5)

start = time()
random_search.fit(X, y)
print("RandomizedSearchCV took %.2f seconds for %d candidates"
      " parameter settings." % ((time() - start), n_iter_search))
report(random_search.cv_results_)
```

    RandomizedSearchCV took 9.50 seconds for 30 candidates parameter settings.
    Model with rank: 1
    Mean validation score: 0.835 (std: 0.021)
    Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 1, 'min_samples_split': 8, 'n_estimators': 74}
    
    Model with rank: 2
    Mean validation score: 0.831 (std: 0.029)
    Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'min_samples_split': 8, 'n_estimators': 76}
    
    Model with rank: 3
    Mean validation score: 0.824 (std: 0.020)
    Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'min_samples_split': 7, 'n_estimators': 60}
    
    


```python
rf = random_search.best_estimator_.fit(X,y)
```


```python
rf.predict(X)
```




    array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,
           1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,
           1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,
           1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,
           1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,
           0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
           0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
           0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,
           1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,
           0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,
           0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,
           1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,
           0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,
           1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,
           0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,
           0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,
           0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,
           0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,
           1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,
           0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,
           1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,
           1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,
           0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,
           1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
           1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
           0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,
           0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
           0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,
           0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,
           0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,
           1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,
           0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
           0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
           0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,
           0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,
           1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,
           1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)




```python
pd.DataFrame(rf.feature_importances_, index = X.columns
             , columns = ['Feature Importance']).sort_values(by = 'Feature Importance', ascending = False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature Importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Fare</th>
      <td>0.330700</td>
    </tr>
    <tr>
      <th>Age_Fill_Med</th>
      <td>0.280745</td>
    </tr>
    <tr>
      <th>Sex_male</th>
      <td>0.280466</td>
    </tr>
    <tr>
      <th>Pclass</th>
      <td>0.108088</td>
    </tr>
  </tbody>
</table>
</div>




```python
# run rf.predict() on the same columns as train data but using the test data once transformations are complete
```

# Test model using the test dataset

## Import Test data
Import test.csv and save it to dataframe **test_df**


```python
test = pd.read_csv('test.csv')
test_df = pd.DataFrame(test)
test_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>892</td>
      <td>3</td>
      <td>Kelly, Mr. James</td>
      <td>male</td>
      <td>34.5</td>
      <td>0</td>
      <td>0</td>
      <td>330911</td>
      <td>7.8292</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>1</th>
      <td>893</td>
      <td>3</td>
      <td>Wilkes, Mrs. James (Ellen Needs)</td>
      <td>female</td>
      <td>47.0</td>
      <td>1</td>
      <td>0</td>
      <td>363272</td>
      <td>7.0000</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>2</th>
      <td>894</td>
      <td>2</td>
      <td>Myles, Mr. Thomas Francis</td>
      <td>male</td>
      <td>62.0</td>
      <td>0</td>
      <td>0</td>
      <td>240276</td>
      <td>9.6875</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>3</th>
      <td>895</td>
      <td>3</td>
      <td>Wirz, Mr. Albert</td>
      <td>male</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>315154</td>
      <td>8.6625</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>896</td>
      <td>3</td>
      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>
      <td>female</td>
      <td>22.0</td>
      <td>1</td>
      <td>1</td>
      <td>3101298</td>
      <td>12.2875</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Fill NAs with median of training set
test_df["Age_Fill_Med"] = test_df["Age"].fillna(med_age)
test_df["Fare"] = test_df["Fare"].fillna(fare_median)
```


```python
# Convert Embarked and Sex columns to dummy variables
test_df = pd.get_dummies(test_df,columns=['Embarked','Sex'])
```


```python
# Remove unnecessary columns
test_df.drop(['Sex_female', 'Embarked_C' ], axis = 1, inplace = True)
```


```python
# Explore columns for model
df[['Age_Fill_Med','Pclass','Sex_male','Fare']].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age_Fill_Med</th>
      <th>Pclass</th>
      <th>Sex_male</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>29.361582</td>
      <td>2.308642</td>
      <td>0.647587</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>13.019697</td>
      <td>0.836071</td>
      <td>0.477990</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.420000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>22.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>28.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>35.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>80.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Add survival prediction to the test_df dataframe
test_df['Survived'] = rf.predict(test_df[['Age_Fill_Med','Pclass','Sex_male','Fare']])
```


```python
print('Train survival mean:  ' + str(round(df['Survived'].mean(),4)))
print('Test survival rate:  ' +str(round(test_df['Survived'].mean(),4)))
```

    Train survival mean:  0.3838
    Test survival rate:  0.3278
    

# Create and save submission file


```python
submission = test_df[['PassengerId', 'Survived']]
submission.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>892</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>893</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>894</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>895</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>896</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Save submission to csv
# submission.to_csv('AR_Titanic_Submission.csv')
```

# Conclusion
In conclusion, we see that the most important features to surviving the Titanic are age, gender, and fare.
